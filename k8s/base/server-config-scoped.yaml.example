---
apiVersion: mlops.seldon.io/v1alpha1
kind: ServerConfig
metadata:
  name: mlserver-config
  namespace: seldon-system
  labels:
    app.kubernetes.io/name: fraud-detection
    app.kubernetes.io/part-of: ml-platform
    app.kubernetes.io/managed-by: kustomize
spec:
  podSpec:
    containers:
    - name: rclone
      image: docker.io/seldonio/seldon-rclone:2.9.1
      imagePullPolicy: IfNotPresent
      env:
      - name: RCLONE_LOG_LEVEL
        value: INFO
      envFrom:
      # Replace 'your-s3-credentials-secret' with your actual secret name containing:
      # - AWS_ACCESS_KEY_ID
      # - AWS_SECRET_ACCESS_KEY
      # - AWS_DEFAULT_REGION
      # - S3_ENDPOINT_URL (if using MinIO/custom S3)
      - secretRef:
          name: your-s3-credentials-secret
      ports:
      - containerPort: 5572
        name: rclone
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        tcpSocket:
          port: 5572
        timeoutSeconds: 1
      resources:
        limits:
          memory: 128Mi
        requests:
          cpu: 50m
          memory: 128Mi
      volumeMounts:
      - mountPath: /mnt/agent
        name: mlserver-models
      lifecycle:
        preStop:
          httpGet:
            path: terminate
            port: 9007
    - name: agent
      # Replace 'your-registry.com' with your container registry
      # Options: harbor.your-domain.com, docker.io, gcr.io, etc.
      image: your-registry.com/library/seldon-agent:2.9.1
      command:
      - /bin/agent
      args:
      - --tracing-config-path=/mnt/tracing/tracing.json
      env:
      - name: SELDON_SERVER_CAPABILITIES
        value: "mlserver,mlflow,sklearn,xgboost,lightgbm,python,tensorflow,keras,numpy"
      - name: SELDON_SCHEDULER_HOST
        value: "seldon-scheduler"
      - name: SELDON_SCHEDULER_PORT
        value: "9005"
      - name: SELDON_METRICS_PORT
        value: "9006"
      - name: SELDON_DRAINER_PORT
        value: "9007"
      - name: SELDON_READINESS_PORT
        value: "9008"
      - name: SELDON_SERVER_HTTP_PORT
        value: "8080"
      - name: SELDON_SERVER_GRPC_PORT
        value: "8081"
      - name: SELDON_REVERSE_PROXY_HTTP_PORT
        value: "9001"
      - name: SELDON_REVERSE_PROXY_GRPC_PORT
        value: "9501"
      - name: SELDON_SERVER_TYPE
        value: "mlserver"
      - name: SELDON_LOG_LEVEL
        value: "info"
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: MEMORY_REQUEST
        valueFrom:
          resourceFieldRef:
            containerName: mlserver
            resource: requests.memory
      ports:
      - containerPort: 9501
        name: grpc
        protocol: TCP
      - containerPort: 9001
        name: http
        protocol: TCP
      - containerPort: 9006
        name: metrics
        protocol: TCP
      - containerPort: 9008
        name: readiness-port
        protocol: TCP
      readinessProbe:
        failureThreshold: 1
        httpGet:
          path: /ready
          port: 9008
        periodSeconds: 5
      startupProbe:
        failureThreshold: 60
        httpGet:
          path: /ready
          port: 9008
        periodSeconds: 15
      lifecycle:
        preStop:
          httpGet:
            path: terminate
            port: 9007
      volumeMounts:
      - mountPath: /mnt/agent
        name: mlserver-models
      - mountPath: /mnt/config
        name: config-volume
      - mountPath: /mnt/tracing
        name: tracing-config-volume
      resources:
        requests:
          cpu: 100m
          memory: 512Mi
        limits:
          cpu: 250m
          memory: 1Gi
    - name: mlserver
      # Replace 'your-registry.com' with your container registry
      image: your-registry.com/library/mlserver:1.7.0
      env:
      - name: MLSERVER_PARALLEL_WORKERS
        value: "2"
      - name: MLSERVER_MAX_GRPC_WORKERS
        value: "5"
      - name: FRAUD_MODEL_NAMESPACE
        value: "fraud-inference"
      - name: MLSERVER_HTTP_PORT
        value: "8080"
      - name: MLSERVER_GRPC_PORT
        value: "8081"
      - name: MLSERVER_MODELS_DIR
        value: "/mnt/agent/models"
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      - containerPort: 8081
        name: grpc
        protocol: TCP
      - containerPort: 8082
        name: metrics
        protocol: TCP
      readinessProbe:
        httpGet:
          path: /v2/health/ready
          port: 8080
        initialDelaySeconds: 5
        periodSeconds: 5
      livenessProbe:
        httpGet:
          path: /v2/health/live
          port: 8080
        initialDelaySeconds: 30
        periodSeconds: 10
      lifecycle:
        preStop:
          httpGet:
            path: terminate
            port: 9007
      volumeMounts:
      - mountPath: /mnt/agent
        name: mlserver-models
        readOnly: true
      resources:
        requests:
          cpu: 250m
          memory: 1Gi
        limits:
          cpu: 500m
          memory: 2Gi
    serviceAccountName: seldon-server
    terminationGracePeriodSeconds: 120
    volumes:
    - name: config-volume
      configMap:
        name: seldon-agent
    - name: tracing-config-volume
      configMap:
        name: seldon-tracing
  volumeClaimTemplates:
  - name: mlserver-models
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi
